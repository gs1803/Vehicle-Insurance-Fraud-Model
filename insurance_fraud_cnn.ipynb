{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score as f1_score_sk\n",
    "import scikitplot as skplt\n",
    "\n",
    "from lime import lime_image\n",
    "\n",
    "from modules.main_model import create_model\n",
    "from utils.image_manipulation import resize_and_pad, swap_labels\n",
    "from utils.loss_and_scoring import FocalLoss, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = tf.config.list_physical_devices('GPU')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    layers.RandomRotation(0.2),\n",
    "    layers.RandomZoom(0.2),\n",
    "    layers.RandomContrast(0.2)\n",
    "])\n",
    "\n",
    "preprocess_input = tf.keras.applications.efficientnet_v2.preprocess_input\n",
    "\n",
    "IMG_SIZE = (300, 300)\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_metrics_plots(y_test, y_pred, y_pred_proba):\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    skplt.metrics.plot_confusion_matrix(y_test, y_pred, ax=axes[0, 0])\n",
    "    skplt.metrics.plot_roc(y_test, y_pred_proba, ax=axes[0, 1])\n",
    "    skplt.metrics.plot_precision_recall(y_test, y_pred_proba, ax=axes[1, 0])\n",
    "    skplt.metrics.plot_cumulative_gain(y_test, y_pred_proba, ax=axes[1, 1])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'data/train'\n",
    "test_dir = 'data/test'\n",
    "\n",
    "train_dataset = tf.keras.utils.image_dataset_from_directory(train_dir, image_size=IMG_SIZE, batch_size=BATCH_SIZE, seed=50)\n",
    "test_dataset = tf.keras.utils.image_dataset_from_directory(test_dir, image_size=IMG_SIZE, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.map(resize_and_pad).map(swap_labels)\n",
    "test_dataset = test_dataset.map(resize_and_pad).map(swap_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_images = []\n",
    "non_fraud_images = []\n",
    "\n",
    "for images, labels in train_dataset:\n",
    "    for i in range(len(labels)):\n",
    "        if labels[i] == 1:\n",
    "            fraud_images.append(images[i].numpy().astype(\"uint8\"))\n",
    "        elif labels[i] == 0:\n",
    "            non_fraud_images.append(images[i].numpy().astype(\"uint8\"))\n",
    "\n",
    "        if len(fraud_images) >= 13 and len(non_fraud_images) >= 12:\n",
    "            break\n",
    "        \n",
    "    if len(fraud_images) >= 13 and len(non_fraud_images) >= 12:\n",
    "        break\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "for i in range(13):\n",
    "    ax = plt.subplot(5, 5, i + 1)\n",
    "    plt.imshow(fraud_images[i])\n",
    "    plt.title(\"Fraud\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "for i in range(12):\n",
    "    ax = plt.subplot(5, 5, i + 14)\n",
    "    plt.imshow(non_fraud_images[i])\n",
    "    plt.title(\"Non-Fraud\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.concatenate([y.numpy() for _, y in train_dataset])\n",
    "pred_labels = np.concatenate([y.numpy() for _, y in test_dataset])\n",
    "all_labels = np.concatenate((train_labels, pred_labels))\n",
    "\n",
    "class_weights = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(all_labels), y=all_labels)\n",
    "class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "print(\"Class weights:\", class_weight_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(num_classes=2)\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss=FocalLoss(),\n",
    "              metrics=['accuracy', f1_score])\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='f1_score', patience=5, restore_best_weights=True, mode='max')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_dataset,\n",
    "                    epochs=10,\n",
    "                    callbacks=[early_stopping],\n",
    "                    class_weight=class_weight_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('models/cnn_fraud_model_effv2b3.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "ax[0].plot(history.history['accuracy'], label='Accuracy')\n",
    "ax[0].plot(history.history['f1_score'], label='F1 Score')\n",
    "ax[0].set_title('Accuracy and F1 Score')\n",
    "ax[0].set_xlabel('Epoch')\n",
    "ax[0].set_ylabel('Score')\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(history.history['loss'], label='Loss', color='red')\n",
    "ax[1].set_title('Loss')\n",
    "ax[1].set_xlabel('Epoch')\n",
    "ax[1].set_ylabel('Loss')\n",
    "ax[1].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = [], []\n",
    "for batch_images, batch_labels in train_dataset:\n",
    "    images.append(batch_images.numpy())\n",
    "    labels.append(batch_labels.numpy())\n",
    "\n",
    "images = np.concatenate(images, axis=0)\n",
    "labels = np.concatenate(labels, axis=0)\n",
    "\n",
    "k = 5\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "acc_scores = []\n",
    "f1_scores_l = []\n",
    "\n",
    "for train_index, val_index in kf.split(images):\n",
    "    X_train, X_val = images[train_index], images[val_index]\n",
    "    y_train, y_val = labels[train_index], labels[val_index]\n",
    "\n",
    "    model = create_model(num_classes=2)\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  loss=FocalLoss(),\n",
    "                  metrics=['accuracy', f1_score])\n",
    "\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='f1_score', patience=5, restore_best_weights=True, mode='max')\n",
    "\n",
    "    history = model.fit(train_dataset,\n",
    "                    epochs=10,\n",
    "                    callbacks=[early_stopping],\n",
    "                    class_weight=class_weight_dict)\n",
    "\n",
    "    score = model.evaluate(X_val, y_val, verbose=0)\n",
    "    acc_scores.append(score[1])\n",
    "    f1_scores_l.append(score[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_accuracy = np.mean(acc_scores)\n",
    "f1_scores = np.mean(f1_scores_l)\n",
    "print(f'Average Accuracy across {k} folds: {average_accuracy:.4f}, {f1_scores:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_tuners = pd.read_csv('keras_tuner_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_tuners[['num_dense_layers', 'learning_rate', 'train_accuracy', 'val_accuracy', 'train_f1_score', \n",
    "              'val_f1_score', 'train_loss', 'val_loss']].sort_values('val_f1_score', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = keras.models.load_model('models/cnn_fraud_model_effv2b3.keras', custom_objects={'FocalLoss': FocalLoss, 'f1_score': f1_score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_labels = []\n",
    "\n",
    "for images, labels in test_dataset:\n",
    "    raw_labels.append(labels.numpy())\n",
    "\n",
    "true_labels = np.concatenate(raw_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(x=test_predictions[:, 1], hue=true_labels, stat=\"density\", common_norm=False)\n",
    "plt.title('Prediction Probabilities vs True Labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_threshold = pd.DataFrame()\n",
    "\n",
    "for i, th in enumerate(np.arange(0.4, 0.61, 0.01)):\n",
    "    test_labels_l =  (test_predictions > th).astype(int)[:, 1]\n",
    "    df_threshold.loc[i, 'threshold'] = th\n",
    "    df_threshold.loc[i, 'accuarcy'] = accuracy_score(true_labels, test_labels_l)\n",
    "    df_threshold.loc[i, 'precision'] = precision_score(true_labels, test_labels_l)\n",
    "    df_threshold.loc[i, 'recall'] = recall_score(true_labels, test_labels_l)\n",
    "    df_threshold.loc[i, 'f1_score'] = f1_score_sk(true_labels, test_labels_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(df_threshold.sort_values(['f1_score'], ascending=False).head(), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels = (test_predictions > 0.53).astype(int)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(true_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_metrics_plots(true_labels, pred_labels, test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_images = []\n",
    "non_fraud_images = []\n",
    "fraud_labels = []\n",
    "non_fraud_labels = []\n",
    "\n",
    "for images, true_labels_img in test_dataset:\n",
    "    true_labels_img = true_labels_img.numpy()\n",
    "\n",
    "    for i in range(len(images)):\n",
    "        if true_labels_img[i] == 1 and pred_labels[i] == 1 and len(fraud_images) < 13:\n",
    "            fraud_images.append(images[i].numpy().astype(\"uint8\"))\n",
    "            fraud_labels.append(pred_labels[i])\n",
    "\n",
    "        elif true_labels_img[i] == 0 and pred_labels[i] == 0 and len(non_fraud_images) < 12:\n",
    "            non_fraud_images.append(images[i].numpy().astype(\"uint8\"))\n",
    "            non_fraud_labels.append(pred_labels[i])\n",
    "\n",
    "        if len(fraud_images) >= 13 and len(non_fraud_images) >= 12:\n",
    "            break\n",
    "\n",
    "    if len(fraud_images) >= 12 and len(non_fraud_images) >= 12:\n",
    "        break\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "for i in range(13):\n",
    "    ax = plt.subplot(5, 5, i + 1)\n",
    "    plt.imshow(fraud_images[i])\n",
    "    plt.title(f\"Predicted: {fraud_labels[i]}, True: 1\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "for i in range(12):\n",
    "    ax = plt.subplot(5, 5, i + 14)\n",
    "    plt.imshow(non_fraud_images[i])\n",
    "    plt.title(f\"Predicted: {non_fraud_labels[i]}, True: 0\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lime For Explainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_images = []\n",
    "non_fraud_images = []\n",
    "fraud_labels = []\n",
    "non_fraud_labels = []\n",
    "\n",
    "for images, true_labels_img in test_dataset:\n",
    "    true_labels_img = true_labels_img.numpy()\n",
    "\n",
    "    for i in range(len(images)):\n",
    "        if true_labels_img[i] == 1 and pred_labels[i] == 1 and len(fraud_images) < 3:\n",
    "            fraud_images.append(images[i].numpy().astype(\"uint8\"))\n",
    "            fraud_labels.append(pred_labels[i])\n",
    "\n",
    "        elif true_labels_img[i] == 0 and pred_labels[i] == 0 and len(non_fraud_images) < 3:\n",
    "            non_fraud_images.append(images[i].numpy().astype(\"uint8\"))\n",
    "            non_fraud_labels.append(pred_labels[i])\n",
    "\n",
    "        if len(fraud_images) >= 3 and len(non_fraud_images) >= 3:\n",
    "            break\n",
    "\n",
    "    if len(fraud_images) >= 3 and len(non_fraud_images) >= 3:\n",
    "        break\n",
    "\n",
    "explainer = lime_image.LimeImageExplainer()\n",
    "\n",
    "for i in range(3):\n",
    "    explanation_fraud = explainer.explain_instance(fraud_images[i], lambda x: model.predict(x, verbose=0), \n",
    "                                                   top_labels=5, hide_color=0, num_samples=1000, random_seed=50)\n",
    "\n",
    "    top_label_fraud = explanation_fraud.top_labels[0]\n",
    "    temp_fraud, mask_fraud = explanation_fraud.get_image_and_mask(top_label_fraud, positive_only=True, num_features=10, hide_rest=False)\n",
    "\n",
    "    temp_fraud = (temp_fraud - temp_fraud.min()) / (temp_fraud.max() - temp_fraud.min())\n",
    "    temp_fraud = (temp_fraud * 255).astype(np.uint8)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(fraud_images[i])\n",
    "    plt.title(f\"Fraud - Predicted: {fraud_labels[i]}, True: 1\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(temp_fraud)\n",
    "    plt.imshow(mask_fraud, alpha=0.5, cmap='jet')\n",
    "    plt.title(f\"LIME: {top_label_fraud}\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "for i in range(3):\n",
    "    explanation_non_fraud = explainer.explain_instance(non_fraud_images[i], lambda x: model.predict(x, verbose=0),\n",
    "                                                       top_labels=5, hide_color=0, num_samples=1000, random_seed=50)\n",
    "\n",
    "    top_label_non_fraud = explanation_non_fraud.top_labels[0]\n",
    "    temp_non_fraud, mask_non_fraud = explanation_non_fraud.get_image_and_mask(top_label_non_fraud, positive_only=True, num_features=10, hide_rest=False)\n",
    "\n",
    "    temp_non_fraud = (temp_non_fraud - temp_non_fraud.min()) / (temp_non_fraud.max() - temp_non_fraud.min())\n",
    "    temp_non_fraud = (temp_non_fraud * 255).astype(np.uint8)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(non_fraud_images[i])\n",
    "    plt.title(f\"Non-Fraud - Predicted: {non_fraud_labels[i]}, True: 0\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(temp_non_fraud)\n",
    "    plt.imshow(mask_non_fraud, alpha=0.5, cmap='jet')\n",
    "    plt.title(f\"LIME: {top_label_non_fraud}\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
